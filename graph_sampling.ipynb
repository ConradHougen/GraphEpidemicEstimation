{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as la\n",
    "\n",
    "def get_num_vertices(adj_mat):\n",
    "    return adj_mat.shape[0]\n",
    "\n",
    "def get_num_edges(adj_mat):\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    upper_tri_idx = np.triu_indices(n, 1)\n",
    "    return np.count_nonzero(adj_mat[upper_tri_idx])\n",
    "\n",
    "def compute_graph_volume(adj_mat):\n",
    "    return float(np.sum(adj_mat))/2.0\n",
    "\n",
    "def compute_graph_density(adj_mat):\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    m = get_num_edges(adj_mat)\n",
    "    \n",
    "    density = float(2 * m)/float(n * (n - 1))\n",
    "    return density\n",
    "\n",
    "def reject_outliers(data, m=2):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "\n",
    "def compute_degree_distribution(adj_mat):\n",
    "    # Assuming a simple, possibly weighted graph, degree of each vertex\n",
    "    # will be the sum along one axis\n",
    "    deg_arr = np.sum(adj_mat, axis=0)\n",
    "    return deg_arr\n",
    "\n",
    "def compute_average_degree(adj_mat):\n",
    "    deg_arr = compute_degree_distribution(adj_mat)\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    \n",
    "    avg_deg = float(sum(deg_arr))/float(n)\n",
    "    return avg_deg\n",
    "\n",
    "def display_degree_distribution(adj_mat, dataset_name, override_min, num_bins_log_log=50):\n",
    "    deg_arr = compute_degree_distribution(adj_mat)\n",
    "    #deg_arr = reject_outliers(deg_arr)\n",
    "    # Display histogram of degree distribution\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.hist(deg_arr, bins='auto')\n",
    "    plt.title('Deg Dist of {}'.format(dataset_name))\n",
    "    \n",
    "    # Display histogram of degree distribution with log-log plot\n",
    "    plt.subplot(2, 1, 2)\n",
    "    max_val = np.amax(adj_mat)\n",
    "    min_val = np.amin(adj_mat[adj_mat > override_min])\n",
    "    print min_val\n",
    "    pow_ten_min = 10 ** (np.floor(np.log10(min_val+0.1)))\n",
    "    pow_ten_max = 10 ** (np.ceil(np.log10(max_val)))\n",
    "    plt.hist(deg_arr, bins=np.logspace(np.log10(pow_ten_min), np.log10(pow_ten_max), num_bins_log_log))\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.title('Log-Log Deg Dist of {}'.format(dataset_name))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def get_neighborhood_set_of_node(adj_mat, node):\n",
    "    nbrhd = []\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    \n",
    "    # Find all edges connecting node to other nodes\n",
    "    for j in range(0, n):\n",
    "        if adj_mat[node][j] != 0:\n",
    "            nbrhd.append(j)\n",
    "    return nbrhd\n",
    "    \n",
    "def compute_clustering_coefficient(adj_mat, node):\n",
    "    # Get the degree of the node\n",
    "    node_deg = compute_degree_distribution(adj_mat)[node]\n",
    "    \n",
    "    if node_deg <= 1:\n",
    "        #print(\"Node {} has degree {}. CC is undefined\".format(node, node_deg))\n",
    "        return 0\n",
    "    \n",
    "    # Get the neighborhood set of the node\n",
    "    nbrhd = get_neighborhood_set_of_node(adj_mat, node)\n",
    "       \n",
    "    # Get reduced neighborhood matrix of node\n",
    "    nbrhd_matrix = adj_mat[:, nbrhd]\n",
    "    nbrhd_matrix = nbrhd_matrix[nbrhd, :]\n",
    "       \n",
    "    # Count the number of triangles formed by the neighborhood set\n",
    "    num_triangles = np.sum(nbrhd_matrix)\n",
    "\n",
    "    # Compute the clustering coefficient and add it to the array\n",
    "    clustering_coefficient = float(2 * num_triangles)/float(node_deg * (node_deg - 1))\n",
    "    return clustering_coefficient\n",
    "    \n",
    "def compute_all_clustering_coefficients(adj_mat):\n",
    "    # For each node in the graph, compute the clustering coefficient and store\n",
    "    # it in an array\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    cluster_coeff_arr = np.zeros((n, 1))\n",
    "    \n",
    "    for node in range(0, n):\n",
    "        # Compute the clustering coefficient and add it to the array\n",
    "        cluster_coeff_arr[node] = compute_clustering_coefficient(adj_mat, node)\n",
    "        \n",
    "    return cluster_coeff_arr    \n",
    "\n",
    "def display_clustering_coefficient_dist(adj_mat, dataset_name, num_bins_log_log=50):\n",
    "    cluster_coeff_arr = compute_all_clustering_coefficients(adj_mat)\n",
    "    #cluster_coeff_arr = reject_outliers(cluster_coeff_arr)\n",
    "    # Display histogram of clustering coefficients\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.hist(cluster_coeff_arr, bins='auto')\n",
    "    plt.title('CC Dist of {}'.format(dataset_name))\n",
    "    \n",
    "    # Display histogram of degree distribution with log-log plot\n",
    "    plt.subplot(2, 1, 2)\n",
    "    max_val = np.amax(cluster_coeff_arr)\n",
    "    min_val = np.amin(cluster_coeff_arr)\n",
    "    pow_ten_min = 10 ** (np.floor(np.log10(min_val+0.1)))\n",
    "    pow_ten_max = 10 ** (np.ceil(np.log10(max_val)))\n",
    "    plt.hist(deg_arr, bins=np.logspace(np.log10(pow_ten_min), np.log10(pow_ten_max), num_bins_log_log))\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.title('Log-Log CC Dist of {}'.format(dataset_name))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def compute_average_clustering_coefficient(adj_mat):\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    avg_cc = float(np.sum(compute_all_clustering_coefficients(adj_mat)))/float(n)\n",
    "    return avg_cc\n",
    "\n",
    "def indices(a, func):\n",
    "    return [i for (i, val) in enumerate(a) if func(val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Sampling Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Sampling (Induced Subgraph Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Takes an adjacency matrix, A, and fraction of nodes to be sampled, f.  At each \n",
    "# step, selects a node to be sampled, until f fraction of nodes have been chosen.\n",
    "# Then, pick all edges induced by the set of chosen nodes\n",
    "def graph_sampling_algo_uniform_node_sampling(A, f):\n",
    "    n = A.shape[0]\n",
    "    A_s = np.zeros(A.shape)    \n",
    "    if f > 1 or f < 0:\n",
    "        print \"[UNS] Warning: f param not a proper fraction in uniform NS algo\"\n",
    "        return A\n",
    "    \n",
    "    # Use the unweighted adjacency matrix\n",
    "    adj_mat = np.where(A != 0, 1, 0)\n",
    "    num_edges_total = compute_graph_volume(adj_mat)\n",
    "    num_edges_to_sample = np.ceil(f * num_edges_total)\n",
    "    \n",
    "    \n",
    "    V = np.arange(n)\n",
    "    np.random.shuffle(V)\n",
    "    V_s = []\n",
    "    j = 0\n",
    "    num_edges_sampled = 0\n",
    "    \n",
    "    while j < n and num_edges_sampled < num_edges_to_sample:\n",
    "        current_node = V[j]\n",
    "        V_s.append(current_node)\n",
    "        num_edges_sampled += np.sum(adj_mat[:, current_node])\n",
    "        j += 1\n",
    "        \n",
    "    for node in V_s:\n",
    "        A_s[:, node] = A[:, node]\n",
    "        A_s[node, :] = A[node, :]\n",
    "    \n",
    "    return A_s\n",
    " \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Sampling (Incident Subgraph Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_sampling_algo_uniform_edge_sampling(A, f):\n",
    "    n = A.shape[0]\n",
    "    A_s = np.zeros(A.shape)\n",
    "    \n",
    "    if f > 1 or f < 0:\n",
    "        print \"[UES] Warning: f param not a proper fraction\"\n",
    "        return A\n",
    "    \n",
    "    # Use the unweighted matrix\n",
    "    adj_mat = np.where(A != 0, 1, 0)\n",
    "    num_edges_total = compute_graph_volume(adj_mat)\n",
    "    num_edges_to_sample = np.ceil(f * num_edges_total)\n",
    "    \n",
    "    j = 0\n",
    "    num_edges_sampled = 0\n",
    "    \n",
    "    # Get all the locations of unique edges\n",
    "    A_triu = np.triu(A)\n",
    "    E = np.nonzero(A_triu)\n",
    "    E = zip(E[0], E[1])\n",
    "    np.random.shuffle(E)\n",
    "    \n",
    "    while j < len(E) and num_edges_sampled < num_edges_to_sample:\n",
    "        current_edge = E[j]\n",
    "        A_s[current_edge] = A[current_edge]\n",
    "        A_s[current_edge[::-1]] = A[current_edge[::-1]]\n",
    "        num_edges_sampled += 1\n",
    "        j += 1\n",
    "        \n",
    "    return A_s\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A: possibly weighted adjacency matrix (weights WILL affect exploration,\n",
    "#    but will not affect the number of edges sampled)\n",
    "# f: fraction of edges to sample\n",
    "# q: probability of randomly restarting at a new node\n",
    "def graph_sampling_algo_metropolis_hastings_random_walk(A, f, q):\n",
    "    n = A.shape[0]\n",
    "    A_s = np.copy(A)\n",
    "    \n",
    "    if f > 1 or f < 0:\n",
    "        print \"[MHRW] Warning: f param not a proper fraction\"\n",
    "        return A\n",
    "    \n",
    "    if q > 1 or q < 0:\n",
    "        print \"[MHRW] Warning: q param is not a proper probability\"\n",
    "        return A\n",
    "    \n",
    "    adj_mat = np.where(A != 0, 1, 0)\n",
    "    num_edges_total = compute_graph_volume(adj_mat)\n",
    "    num_edges_to_sample = np.ceil(f * num_edges_total)\n",
    "        \n",
    "    # Select a starting node\n",
    "    V = np.arange(n)\n",
    "    np.random.shuffle(V)\n",
    "    current_node = V[0]\n",
    "    V_s = [current_node]\n",
    "    num_edges_sampled = np.sum(adj_mat[:, current_node])\n",
    "    A_s[:, current_node] = 0\n",
    "    A_s[current_node, :] = 0\n",
    "    \n",
    "    while num_edges_sampled < num_edges_to_sample:\n",
    "        \n",
    "        # Determine whether to jump to a new random node or sample a neighbor\n",
    "        r_decider = np.random.uniform()\n",
    "        if r_decider < q:\n",
    "            # Choose random restart node\n",
    "            inverse_V_s = list(set(V) - set(V_s))\n",
    "            np.random.shuffle(inverse_V_s)\n",
    "            current_node = inverse_V_s[0]\n",
    "            V_s.append(current_node)\n",
    "            num_edges_sampled += np.sum(adj_mat[:, current_node])\n",
    "            A_s[:, current_node] = 0\n",
    "            A_s[current_node, :] = 0\n",
    "            \n",
    "        else:\n",
    "            # Select one of the neighbors of the current node based on proportion\n",
    "            # of edge weight over weighted degree\n",
    "            nbrhd = get_neighborhood_set_of_node(adj_mat, current_node)\n",
    "            \n",
    "            # If the neighborhood is empty, force a jump to a new node\n",
    "            if not nbrhd:\n",
    "                # Choose random restart node\n",
    "                inverse_V_s = list(set(V) - set(V_s))\n",
    "                np.random.shuffle(inverse_V_s)\n",
    "                current_node = inverse_V_s[0]\n",
    "                V_s.append(current_node)\n",
    "                num_edges_sampled += np.sum(adj_mat[:, current_node])\n",
    "                A_s[:, current_node] = 0\n",
    "                A_s[current_node, :] = 0\n",
    "                continue\n",
    "            \n",
    "            degree = np.sum(A[:, current_node])\n",
    "            r_decider = np.random.uniform() * degree\n",
    "            cumulative_deg = 0\n",
    "            for nbr_node in nbrhd:\n",
    "                cumulative_deg += A[current_node, nbr_node]\n",
    "                if cumulative_deg > r_decider:\n",
    "                    current_node = nbr_node\n",
    "                    V_s.append(current_node)\n",
    "                    num_edges_sampled += np.sum(adj_mat[:, current_node])\n",
    "                    A_s[:, current_node] = 0\n",
    "                    A_s[current_node, :] = 0\n",
    "                    break\n",
    "        \n",
    "    # Create A_s by inverting\n",
    "    A_s = np.copy(A) - A_s\n",
    "                        \n",
    "    return A_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frontier Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A: possibly weighted adjacency matrix (weights WILL affect exploration,\n",
    "#    but will not affect the number of edges sampled)\n",
    "# f: fraction of edges to sample\n",
    "# d: deimension of the multi-dimensional random walk\n",
    "def graph_sampling_algo_frontier_sampling(A, f, d):\n",
    "    n = A.shape[0]\n",
    "    A_s = np.zeros(A.shape)\n",
    "    \n",
    "    if f > 1 or f < 0:\n",
    "        print \"[FS] Warning: f param not a proper fraction\"\n",
    "        return A\n",
    "    \n",
    "    if d < 0:\n",
    "        print \"[FS] Warning: d param must be a positive integer\"\n",
    "        return A\n",
    "        \n",
    "    adj_mat = np.where(A != 0, 1, 0)\n",
    "    num_edges_total = compute_graph_volume(adj_mat)\n",
    "    num_edges_to_sample = np.ceil(f * num_edges_total)\n",
    "    \n",
    "    # Allocate list of random walker current nodes\n",
    "    L = np.random.randint(0, n, d)\n",
    "    \n",
    "    # Keep a list of node degrees associated with the nodes in L\n",
    "    degrees = np.zeros((d, 1))\n",
    "    for j in range(0, d):\n",
    "        degrees[j] += np.sum(A[L[j], :])\n",
    "    \n",
    "    num_edges_sampled = 0\n",
    "    step = 0\n",
    "    while num_edges_sampled < num_edges_to_sample and step <= n**3:\n",
    "        # Compute sum of degrees of current nodes\n",
    "        tot_deg = np.sum(degrees)\n",
    "        \n",
    "        # Prepare bin edges\n",
    "        bin_edges = np.zeros((d+1, 1))\n",
    "        for ii in range(0, d):\n",
    "            bin_edges[ii+1] = bin_edges[ii] + float(degrees[ii])/float(tot_deg)\n",
    "        if bin_edges[d] != 1:\n",
    "            bin_edges[d] = 1.0\n",
    "        \n",
    "        # Use bins to choose node according to proabilities weighted by node deg\n",
    "        r = np.random.uniform()\n",
    "        u_idx_in_L = np.max(np.nonzero(np.where(bin_edges <= r, 1, 0)))\n",
    "        u = L[u_idx_in_L]\n",
    "        \n",
    "        # Get neighborhood of current active random walker\n",
    "        nbrhd = get_neighborhood_set_of_node(adj_mat, u)\n",
    "        # Select one of the neighbors, uniformly at random\n",
    "        n_neighbors = len(nbrhd)\n",
    "        v = nbrhd[np.random.randint(0, n_neighbors)]\n",
    "        \n",
    "        # Update random walker list and degrees\n",
    "        L[u_idx_in_L] = v\n",
    "        degrees[u_idx_in_L] = np.sum(A[v, :])\n",
    "        \n",
    "        # Add the selected edge to A_s if not already present\n",
    "        if A_s[u, v] == 0:\n",
    "            A_s[u, v] = A[u, v]\n",
    "            A_s[v, u] = A[v, u]\n",
    "            num_edges_sampled += 1\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    return A_s\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowball Expansion Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_neighb(A, S, node_idx):\n",
    "    nn = A.shape[0]\n",
    "    \n",
    "    nbrS = []\n",
    "    nbrSBAR = []\n",
    "    for ii in range(0, nn):\n",
    "        if A[node_idx, ii] != 0:\n",
    "            if not ii in S:\n",
    "                nbrSBAR.append(ii)\n",
    "            else:\n",
    "                nbrS.append(ii)\n",
    "    \n",
    "    return nbrS, nbrSBAR\n",
    "    \n",
    "\n",
    "def find_boundary_nodes(A, S):\n",
    "    nn = A.shape[0]\n",
    "    magS = len(S)\n",
    "    \n",
    "    nbrS = []\n",
    "    nbrSBAR = []\n",
    "    for ii in range(0, magS):\n",
    "        for jj in range(0, nn):\n",
    "            if A[S[ii], jj] != 0:\n",
    "                if not jj in S:\n",
    "                    nbrSBAR.append(jj)\n",
    "                else:\n",
    "                    nbrS.append(jj)\n",
    "                    \n",
    "    return nbrS, nbrSBAR\n",
    "\n",
    "def choose_optimal_node(A, S):\n",
    "    nS, nSBAR = find_boundary_nodes(A, S)\n",
    "    \n",
    "    nSBAR_size = len(nSBAR)\n",
    "    \n",
    "    if nSBAR_size == 0:\n",
    "        print \"[SES] There are no neighbors to S outside of S\"\n",
    "        return -1\n",
    "    \n",
    "    XSN_factor = np.zeros((nSBAR_size, 1))\n",
    "    # For each node just outside S...\n",
    "    for i in range(0, nSBAR_size):\n",
    "        # Find its neighbors\n",
    "        t_neighb, t_neighbSBAR = find_neighb(A, S, nSBAR[i])\n",
    "        XSN_factor[i] = len(t_neighbSBAR)\n",
    "        \n",
    "    possible_nodes = indices(XSN_factor, lambda x: x == x.max())\n",
    "    p_sz = len(possible_nodes)\n",
    "    \n",
    "    return nSBAR[possible_nodes[np.random.randint(0, p_sz)]]\n",
    "\n",
    "\n",
    "# A: possibly weighted adjacency matrix (weights WILL affect exploration,\n",
    "#    but will not affect the number of edges sampled)\n",
    "# f: fraction of edges to sample\n",
    "def graph_sampling_algo_snowball_expansion_sampling(A, f):\n",
    "    n = A.shape[0]\n",
    "    A_s = np.copy(A)\n",
    "    \n",
    "    if f > 1 or f < 0:\n",
    "        print \"[SES] Warning: f param not a proper fraction\"\n",
    "        return A\n",
    "    \n",
    "    adj_mat = np.where(A != 0, 1, 0)\n",
    "    num_edges_total = compute_graph_volume(adj_mat)\n",
    "    num_edges_to_sample = np.ceil(f * num_edges_total)\n",
    "    \n",
    "    # Select starting node from discrete uniform\n",
    "    node_idx = np.random.randint(0, n)\n",
    "    \n",
    "    # Create a list of sampled nodes\n",
    "    S = [node_idx]\n",
    "    \n",
    "    # Keep track of number of edges sampled\n",
    "    num_edges_sampled = 0\n",
    "    \n",
    "    while num_edges_sampled < num_edges_to_sample:\n",
    "        # Choose the optimal expansion node and add it to the sample\n",
    "        node_idx = choose_optimal_node(A, S)\n",
    "            \n",
    "        if node_idx >= 0:\n",
    "            S.append(node_idx)\n",
    "            num_edges_sampled += np.sum(adj_mat[:, node_idx])\n",
    "            A_s[:, node_idx] = 0\n",
    "            A_s[node_idx, :] = 0\n",
    "        elif f == 1:\n",
    "            break\n",
    "        else:\n",
    "            # Not a connected graph, so start somewhere else\n",
    "            choices = list(set(np.arange(n)) - set(S))\n",
    "            l_choices = len(choices)\n",
    "            if l_choices <= 0:\n",
    "                print \"[SES] Error trying to restart\"\n",
    "                return A\n",
    "            else:\n",
    "                print \"[SES] Restarting in new location\"\n",
    "                node_idx = choices[np.random.randint(0, l_choices)]\n",
    "                S.append(node_idx)\n",
    "                num_edges_sampled += sum(adj_mat[:, node_idx])\n",
    "                A_s[:, node_idx] = 0\n",
    "                A_s[node_idx, :] = 0\n",
    "                \n",
    "    # Invert to give the proper sampled graph\n",
    "    A_s = np.copy(A) - A_s\n",
    "    \n",
    "    # Trim down A_s by randomly removing edges\n",
    "    E_s = np.nonzero(A_s)\n",
    "    E_s = zip(E_s[0], E_s[1])\n",
    "    while num_edges_sampled > num_edges_to_sample + 2:\n",
    "        e_to_remove = np.random.randint(0, len(E_s))\n",
    "        i, j = E_s[e_to_remove]\n",
    "        # Remove the edge from A_s\n",
    "        A_s[i, j] = 0\n",
    "        A_s[j, i] = 0\n",
    "        # Remove the edge from the edge list\n",
    "        del E_s[e_to_remove]\n",
    "        # Decrement the number of edges sampled\n",
    "        num_edges_sampled -= 1\n",
    "        \n",
    "    return A_s        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest Fire Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def burn(A, A_s, p, num_edges_sampled, num_edges_to_sample, node_idx):\n",
    "    \n",
    "    if num_edges_sampled <= num_edges_to_sample:\n",
    "        n = A.shape[0]\n",
    "        adj_mat = np.where(A != 0, 1, 0)\n",
    "\n",
    "        burn_list = []\n",
    "        for i in range(0, n):\n",
    "            if A[node_idx, i] != 0 and A_s[node_idx, i] == 0:\n",
    "                rndm_num = np.random.uniform()\n",
    "                if rndm_num < p:\n",
    "                    burn_list.append(i)\n",
    "\n",
    "        burn_num = len(burn_list)\n",
    "        # Base case: If no edges to burn, we are done\n",
    "        if burn_num == 0:\n",
    "            return A_s, num_edges_sampled\n",
    "        # Base case: add edge to sample\n",
    "        elif burn_num == 1:\n",
    "            A_s[node_idx, burn_list[0]] = A[node_idx, burn_list[0]]\n",
    "            A_s[burn_list[0], node_idx] = A_s[burn_list[0], node_idx]\n",
    "            num_edges_sampled += 1\n",
    "        # Recursive case: randomly choose which incident edge to begin with, and\n",
    "        # burn each possible edge, in order\n",
    "        else:\n",
    "            np.random.shuffle(burn_list)\n",
    "            for j in range(0, burn_num):\n",
    "                A_s[node_idx, burn_list[j]] = A[node_idx, burn_list[j]]\n",
    "                A_s[burn_list[j], node_idx] = A[burn_list[j], node_idx]\n",
    "                num_edges_sampled += 1\n",
    "                burn(A, A_s, p, num_edges_sampled,num_edges_to_sample, burn_list[j])\n",
    "\n",
    "        return A_s, num_edges_sampled\n",
    "\n",
    "\n",
    "# A: possibly weighted adjacency matrix (weights WILL affect exploration,\n",
    "#    but will not affect the number of edges sampled)\n",
    "# f: fraction of edges to sample\n",
    "# p: probability of adding each single incident edge to the sample\n",
    "def graph_sampling_algo_forest_fire_sampling(A, f, p):\n",
    "    n = A.shape[0]\n",
    "    A_s = np.zeros(A.shape)\n",
    "    \n",
    "    if f > 1 or f < 0:\n",
    "        print \"[FFS] Warning: f param not a proper fraction\"\n",
    "        return A\n",
    "    \n",
    "    adj_mat = np.where(A != 0, 1, 0)\n",
    "    num_edges_total = compute_graph_volume(adj_mat)\n",
    "    num_edges_to_sample = np.ceil(f * num_edges_total)\n",
    "    \n",
    "    # Restart burn process as often as necessary to reach sampling budget\n",
    "    num_edges_sampled = 0\n",
    "    while num_edges_sampled <= num_edges_to_sample:\n",
    "        # Select a random starting node and burn from there\n",
    "        node_idx = np.random.randint(0, n)\n",
    "        # Recursively burn links\n",
    "        A_s, num_edges_sampled = burn(A, A_s, p, num_edges_sampled, num_edges_to_sample, node_idx)\n",
    "        \n",
    "    return A_s\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3, 4],\n",
       "       [2, 0, 3, 4],\n",
       "       [3, 3, 0, 4],\n",
       "       [4, 4, 4, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.array([[0, 2, 3, 4],\n",
    "              [2, 0, 3, 4],\n",
    "              [3, 3, 0, 4],\n",
    "              [4, 4, 4, 0]])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 4.],\n",
       "       [0., 0., 0., 4.],\n",
       "       [0., 0., 0., 4.],\n",
       "       [4., 4., 4., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sampling_algo_uniform_node_sampling(z, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 3., 4.],\n",
       "       [0., 3., 0., 4.],\n",
       "       [0., 4., 4., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sampling_algo_uniform_edge_sampling(z, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 3, 0],\n",
       "       [0, 0, 3, 0],\n",
       "       [3, 3, 0, 4],\n",
       "       [0, 0, 4, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sampling_algo_metropolis_hastings_random_walk(z, 0.5, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 0., 4.],\n",
       "       [2., 0., 0., 4.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [4., 4., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sampling_algo_frontier_sampling(z, 0.5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 0],\n",
       "       [2, 0, 3, 4],\n",
       "       [0, 3, 0, 0],\n",
       "       [0, 4, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sampling_algo_snowball_expansion_sampling(z, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 3., 4.],\n",
       "       [2., 0., 3., 4.],\n",
       "       [3., 3., 0., 4.],\n",
       "       [4., 4., 4., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sampling_algo_forest_fire_sampling(z, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
