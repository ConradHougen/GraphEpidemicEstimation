{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as la\n",
    "\n",
    "def get_num_vertices(adj_mat):\n",
    "    return adj_mat.shape[0]\n",
    "\n",
    "def get_num_edges(adj_mat):\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    upper_tri_idx = np.triu_indices(n, 1)\n",
    "    return np.count_nonzero(adj_mat[upper_tri_idx])\n",
    "\n",
    "def compute_graph_volume(adj_mat):\n",
    "    return float(np.sum(adj_mat))/2.0\n",
    "\n",
    "def compute_graph_density(adj_mat):\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    m = get_num_edges(adj_mat)\n",
    "    \n",
    "    density = float(2 * m)/float(n * (n - 1))\n",
    "    return density\n",
    "\n",
    "def reject_outliers(data, m=2):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "\n",
    "def compute_degree_distribution(adj_mat):\n",
    "    # Assuming a simple, possibly weighted graph, degree of each vertex\n",
    "    # will be the sum along one axis\n",
    "    deg_arr = np.sum(adj_mat, axis=0)\n",
    "    return deg_arr\n",
    "\n",
    "def compute_average_degree(adj_mat):\n",
    "    deg_arr = compute_degree_distribution(adj_mat)\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    \n",
    "    avg_deg = float(sum(deg_arr))/float(n)\n",
    "    return avg_deg\n",
    "\n",
    "def display_degree_distribution(adj_mat, dataset_name, override_min, num_bins_log_log=50):\n",
    "    deg_arr = compute_degree_distribution(adj_mat)\n",
    "    #deg_arr = reject_outliers(deg_arr)\n",
    "    # Display histogram of degree distribution\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.hist(deg_arr, bins='auto')\n",
    "    plt.title('Deg Dist of {}'.format(dataset_name))\n",
    "    \n",
    "    # Display histogram of degree distribution with log-log plot\n",
    "    plt.subplot(2, 1, 2)\n",
    "    max_val = np.amax(adj_mat)\n",
    "    min_val = np.amin(adj_mat[adj_mat > override_min])\n",
    "    print min_val\n",
    "    pow_ten_min = 10 ** (np.floor(np.log10(min_val+0.1)))\n",
    "    pow_ten_max = 10 ** (np.ceil(np.log10(max_val)))\n",
    "    plt.hist(deg_arr, bins=np.logspace(np.log10(pow_ten_min), np.log10(pow_ten_max), num_bins_log_log))\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.title('Log-Log Deg Dist of {}'.format(dataset_name))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def get_neighborhood_set_of_node(adj_mat, node):\n",
    "    nbrhd = []\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    \n",
    "    # Find all edges connecting node to other nodes\n",
    "    for j in range(0, n):\n",
    "        if adj_mat[node][j] != 0:\n",
    "            nbrhd.append(j)\n",
    "    return nbrhd\n",
    "    \n",
    "def compute_clustering_coefficient(adj_mat, node):\n",
    "    # Get the degree of the node\n",
    "    node_deg = compute_degree_distribution(adj_mat)[node]\n",
    "    \n",
    "    if node_deg <= 1:\n",
    "        #print(\"Node {} has degree {}. CC is undefined\".format(node, node_deg))\n",
    "        return 0\n",
    "    \n",
    "    # Get the neighborhood set of the node\n",
    "    nbrhd = get_neighborhood_set_of_node(adj_mat, node)\n",
    "       \n",
    "    # Get reduced neighborhood matrix of node\n",
    "    nbrhd_matrix = adj_mat[:, nbrhd]\n",
    "    nbrhd_matrix = nbrhd_matrix[nbrhd, :]\n",
    "       \n",
    "    # Count the number of triangles formed by the neighborhood set\n",
    "    num_triangles = np.sum(nbrhd_matrix)\n",
    "\n",
    "    # Compute the clustering coefficient and add it to the array\n",
    "    clustering_coefficient = float(2 * num_triangles)/float(node_deg * (node_deg - 1))\n",
    "    return clustering_coefficient\n",
    "    \n",
    "def compute_all_clustering_coefficients(adj_mat):\n",
    "    # For each node in the graph, compute the clustering coefficient and store\n",
    "    # it in an array\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    cluster_coeff_arr = np.zeros((n, 1))\n",
    "    \n",
    "    for node in range(0, n):\n",
    "        # Compute the clustering coefficient and add it to the array\n",
    "        cluster_coeff_arr[node] = compute_clustering_coefficient(adj_mat, node)\n",
    "        \n",
    "    return cluster_coeff_arr    \n",
    "\n",
    "def display_clustering_coefficient_dist(adj_mat, dataset_name, num_bins_log_log=50):\n",
    "    cluster_coeff_arr = compute_all_clustering_coefficients(adj_mat)\n",
    "    #cluster_coeff_arr = reject_outliers(cluster_coeff_arr)\n",
    "    # Display histogram of clustering coefficients\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.hist(cluster_coeff_arr, bins='auto')\n",
    "    plt.title('CC Dist of {}'.format(dataset_name))\n",
    "    \n",
    "    # Display histogram of degree distribution with log-log plot\n",
    "    plt.subplot(2, 1, 2)\n",
    "    max_val = np.amax(cluster_coeff_arr)\n",
    "    min_val = np.amin(cluster_coeff_arr)\n",
    "    pow_ten_min = 10 ** (np.floor(np.log10(min_val+0.1)))\n",
    "    pow_ten_max = 10 ** (np.ceil(np.log10(max_val)))\n",
    "    plt.hist(deg_arr, bins=np.logspace(np.log10(pow_ten_min), np.log10(pow_ten_max), num_bins_log_log))\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.title('Log-Log CC Dist of {}'.format(dataset_name))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def compute_average_clustering_coefficient(adj_mat):\n",
    "    n = get_num_vertices(adj_mat)\n",
    "    avg_cc = float(np.sum(compute_all_clustering_coefficients(adj_mat)))/float(n)\n",
    "    return avg_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the aggregated adjacency matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contact_adj_mat_files = ['output/temporally_aggregate_matrices/contact/agg_mat_InVS13.npy',\n",
    "                         'output/temporally_aggregate_matrices/contact/agg_mat_InVS15.npy',\n",
    "                         'output/temporally_aggregate_matrices/contact/agg_mat_LH10.npy',\n",
    "                         'output/temporally_aggregate_matrices/contact/agg_mat_LyonSchool.npy',\n",
    "                         'output/temporally_aggregate_matrices/contact/agg_mat_SFHH.npy',\n",
    "                         'output/temporally_aggregate_matrices/contact/agg_mat_Thiers13.npy']\n",
    "\n",
    "copresence_adj_mat_files = ['output/temporally_aggregate_matrices/co-presence/agg_mat_pres_InVS13.npy',\n",
    "                            'output/temporally_aggregate_matrices/co-presence/agg_mat_pres_InVS15.npy',\n",
    "                            'output/temporally_aggregate_matrices/co-presence/agg_mat_pres_LH10.npy',\n",
    "                            'output/temporally_aggregate_matrices/co-presence/agg_mat_pres_LyonSchool.npy',\n",
    "                            'output/temporally_aggregate_matrices/co-presence/agg_mat_pres_SFHH.npy',\n",
    "                            'output/temporally_aggregate_matrices/co-presence/agg_mat_pres_Thiers13.npy']\n",
    "\n",
    "agg_mat_InVS13 = np.load(contact_adj_mat_files[0])\n",
    "agg_mat_InVS15 = np.load(contact_adj_mat_files[1])\n",
    "agg_mat_LH10 = np.load(contact_adj_mat_files[2])\n",
    "agg_mat_LyonSchool = np.load(contact_adj_mat_files[3])\n",
    "agg_mat_SFHH = np.load(contact_adj_mat_files[4])\n",
    "agg_mat_Thiers13 = np.load(contact_adj_mat_files[5])\n",
    "\n",
    "agg_mat_pres_InVS13 = np.load(copresence_adj_mat_files[0])\n",
    "agg_mat_pres_InVS15 = np.load(copresence_adj_mat_files[1])\n",
    "agg_mat_pres_LH10 = np.load(copresence_adj_mat_files[2])\n",
    "agg_mat_pres_LyonSchool = np.load(copresence_adj_mat_files[3])\n",
    "agg_mat_pres_SFHH = np.load(copresence_adj_mat_files[4])\n",
    "agg_mat_pres_Thiers13 = np.load(copresence_adj_mat_files[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Sampling Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Sampling (Induced Subgraph Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Takes an adjacency matrix, A, and fraction of nodes to be sampled, f.  At each \n",
    "# step, selects a node to be sampled, until f fraction of nodes have been chosen.\n",
    "# Then, pick all edges induced by the set of chosen nodes\n",
    "def graph_sampling_algo_uniform_node_sampling(A, f):\n",
    "    n = A.shape[0]\n",
    "    A_s = np.copy(A)\n",
    "    print \"n = {}\".format(n)\n",
    "    \n",
    "    if f > 1 or f < 0:\n",
    "        print \"Warning: f param not a proper fraction in uniform NS algo\"\n",
    "        return A\n",
    "    \n",
    "    # Use the unweighted adjacency matrix\n",
    "    adj_mat = np.where(A != 0, 1, 0)\n",
    "    num_edges_total = compute_graph_volume(adj_mat)\n",
    "    num_edges_to_sample = np.ceil(f * num_edges_total)\n",
    "    \n",
    "    print \"num_edges_total:{}, num_edges_to_sample:{}\".format(num_edges_total, num_edges_to_sample)\n",
    "    \n",
    "    V = np.arange(n)\n",
    "    np.random.shuffle(V)\n",
    "    V_s = []\n",
    "    j = 0\n",
    "    num_edges_sampled = 0\n",
    "    \n",
    "    while j < n and num_edges_sampled < num_edges_to_sample:\n",
    "        current_node = V[j]\n",
    "        V_s.append(current_node)\n",
    "        num_edges_sampled += np.sum(np.triu(adj_mat)[:, current_node])\n",
    "        \n",
    "        print \"Append node {} which includes {} edges\".format(current_node, np.sum(np.triu(adj_mat)[:, current_node]))\n",
    "        j += 1\n",
    "        \n",
    "    inverse_V_s = list(set(V) - set(V_s))\n",
    "    A_s[:, inverse_V_s] = 0\n",
    "    A_s[inverse_V_s, :] = 0\n",
    "    \n",
    "    return A_s\n",
    " \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Sampling (Incident Subgraph Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_sampling_algo_uniform_edge_sampling(A, f):\n",
    "    n = A.shape[0]\n",
    "    A_s = np.zeros(A.shape)\n",
    "    \n",
    "    if f > 1 or f < 0:\n",
    "        print \"Warning: f param not a proper fraction in uniform ES algo\"\n",
    "        return A\n",
    "    \n",
    "    # Use the unweighted matrix\n",
    "    adj_mat = np.where(A != 0, 1, 0)\n",
    "    num_edges_total = compute_graph_volume(adj_mat)\n",
    "    num_edges_to_sample = np.ceil(f * num_edges_total)\n",
    "    \n",
    "    j = 0\n",
    "    num_edges_sampled = 0\n",
    "    \n",
    "    # Get all the locations of unique edges\n",
    "    A_triu = np.triu(A)\n",
    "    E = np.nonzero(A_triu)\n",
    "    E = zip(E[0], E[1])\n",
    "    np.random.shuffle(E)\n",
    "    \n",
    "    while j < len(E) and num_edges_sampled < num_edges_to_sample:\n",
    "        current_edge = E[j]\n",
    "        A_s[current_edge] = A[current_edge]\n",
    "        A_s[current_edge[::-1]] = A[current_edge[::-1]]\n",
    "        num_edges_sampled += 1\n",
    "        j += 1\n",
    "        \n",
    "    return A_s\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings Random Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A: possibly weighted adjacency matrix (weights WILL affect exploration,\n",
    "#    but will not affect the number of edges sampled)\n",
    "# f: fraction of edges to sample\n",
    "# q: probability of randomly restarting at a new node\n",
    "def graph_sampling_algo_metropolis_hastings_random_walk(A, f, q):\n",
    "    n = A.shape[0]\n",
    "    A_s = np.copy(A)\n",
    "    \n",
    "    if f > 1 or f < 0:\n",
    "        print \"Warning: f param not a proper fraction in RW algo\"\n",
    "        return A\n",
    "    \n",
    "    if q > 1 or q < 0:\n",
    "        print \"Warning: q param is not a proper probability in RW algo\"\n",
    "        return A\n",
    "    \n",
    "    adj_mat = np.where(A != 0, 1, 0)\n",
    "    num_edges_total = compute_graph_volume(adj_mat)\n",
    "    num_edges_to_sample = np.ceil(f * num_edges_total)\n",
    "        \n",
    "    # Select a starting node\n",
    "    V = np.arange(n)\n",
    "    np.random.shuffle(V)\n",
    "    current_node = V[0]\n",
    "    V_s = [current_node]\n",
    "    num_edges_sampled = np.sum(adj_mat[:, current_node])\n",
    "    A_s[:, current_node] = 0\n",
    "    A_s[current_node, :] = 0\n",
    "    \n",
    "    while num_edges_sampled < num_edges_to_sample:\n",
    "        \n",
    "        # Determine whether to jump to a new random node or sample a neighbor\n",
    "        r_decider = np.random.uniform()\n",
    "        if r_decider < q:\n",
    "            # Choose random restart node\n",
    "            inverse_V_s = list(set(V) - set(V_s))\n",
    "            np.random.shuffle(inverse_V_s)\n",
    "            current_node = inverse_V_s[0]\n",
    "            V_s.append(current_node)\n",
    "            num_edges_sampled += np.sum(adj_mat[:, current_node])\n",
    "            A_s[:, current_node] = 0\n",
    "            A_s[current_node, :] = 0\n",
    "            \n",
    "        else:\n",
    "            # Select one of the neighbors of the current node based on proportion\n",
    "            # of edge weight over weighted degree\n",
    "            nbrhd = get_neighborhood_set_of_node(adj_mat, current_node)\n",
    "            \n",
    "            # If the neighborhood is empty, force a jump to a new node\n",
    "            if not nbrhd:\n",
    "                # Choose random restart node\n",
    "                inverse_V_s = list(set(V) - set(V_s))\n",
    "                np.random.shuffle(inverse_V_s)\n",
    "                current_node = inverse_V_s[0]\n",
    "                V_s.append(current_node)\n",
    "                num_edges_sampled += np.sum(adj_mat[:, current_node])\n",
    "                A_s[:, current_node] = 0\n",
    "                A_s[current_node, :] = 0\n",
    "                continue\n",
    "            \n",
    "            degree = np.sum(A[:, current_node])\n",
    "            r_decider = np.random.uniform() * degree\n",
    "            cumulative_deg = 0\n",
    "            for nbr_node in nbrhd:\n",
    "                cumulative_deg += A[current_node, nbr_node]\n",
    "                if cumulative_deg > r_decider:\n",
    "                    current_node = nbr_node\n",
    "                    V_s.append(current_node)\n",
    "                    num_edges_sampled += np.sum(adj_mat[:, current_node])\n",
    "                    A_s[:, current_node] = 0\n",
    "                    A_s[current_node, :] = 0\n",
    "                    break\n",
    "    \n",
    "    print V_s\n",
    "    \n",
    "    # Create A_s by inverting\n",
    "    A_s = np.copy(A) - A_s\n",
    "                        \n",
    "    return A_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frontier Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A: possibly weighted adjacency matrix (weights WILL affect exploration,\n",
    "#    but will not affect the number of edges sampled)\n",
    "# f: fraction of edges to sample\n",
    "# d: deimension of the multi-dimensional random walk\n",
    "def graph_sampling_algo_frontier_sampling(A, f, d):\n",
    "    n = A.shape[0]\n",
    "    A_s = np.zeros(A.shape)\n",
    "    \n",
    "    if f > 1 or f < 0:\n",
    "        print \"Warning: f param not a proper fraction in FS algo\"\n",
    "        return A\n",
    "    \n",
    "    if d < 0:\n",
    "        print \"Warning: d param must be a positive integer in FS algo\"\n",
    "        return A\n",
    "        \n",
    "    adj_mat = np.where(A != 0, 1, 0)\n",
    "    num_edges_total = compute_graph_volume(adj_mat)\n",
    "    num_edges_to_sample = np.ceil(f * num_edges_total)\n",
    "    \n",
    "    # Allocate list of random walker current nodes\n",
    "    L = np.random.randint(0, n, (d, 1))\n",
    "    \n",
    "    # Keep a list of node degrees associated with the nodes in L\n",
    "    degrees = np.zeros((d, 1))\n",
    "    for j in range(0, d):\n",
    "        degrees[j] += np.sum(A[L[j], :])\n",
    "    \n",
    "    num_edges_sampled = 0\n",
    "    step = 0\n",
    "    while num_edges_sampled < num_edges_to_sample and step <= n**3:\n",
    "        # Compute sum of degrees of current nodes\n",
    "        tot_deg = np.sum(degrees)\n",
    "        \n",
    "        # Prepare bin edges\n",
    "        bin_edges = np.zeros((d+1, 1))\n",
    "        for ii in range(0, d):\n",
    "            bin_edges[ii+1] = bin_edges[ii] + float(degrees[ii])/float(tot_deg)\n",
    "        if bin_edges[d+1] != 1:\n",
    "            bin_edges[d+1] = 1.0\n",
    "        \n",
    "        # Use bins to choose node according to proabilities weighted by node deg\n",
    "        r = np.random.uniform()\n",
    "        u_idx_in_L = np.max(np.nonzero(np.where(bin_edges <= r, 1, 0)))\n",
    "        u = L[u_idx_in_L]\n",
    "        \n",
    "        # Get neighborhood of current active random walker\n",
    "        nbrhd = get_neighborhood_set_of_node(adj_mat, u)\n",
    "        # Select one of the neighbors, uniformly at random\n",
    "        n_neighbors = len(nbrhd)\n",
    "        v = nbrhd[np.random.randint(0, n_neighbors)]\n",
    "        \n",
    "        # Update random walker list and degrees\n",
    "        L[u_idx_in_L] = v\n",
    "        degrees[u_idx_in_L] = np.sum(A[v, :])\n",
    "        \n",
    "        # Add the selected edge to A_s if not already present\n",
    "        if A_s[u, v] == 0:\n",
    "            A_s[u, v] = A[u, v]\n",
    "            A_s[v, u] = A[v, u]\n",
    "            num_edges_sampled += 1\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "    return A_s\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowball Expansion Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_neighb(A, S, node_idx):\n",
    "    nn = A.shape[0]\n",
    "    \n",
    "    nbrS = []\n",
    "    nbrSBAR = []\n",
    "    for ii in range(0, nn):\n",
    "        if A[node_idx, ii] != 0:\n",
    "            if not ii in S:\n",
    "                nbrSBAR.append(ii)\n",
    "            else:\n",
    "                nbrS.append(ii)\n",
    "    \n",
    "    return nbrS, nbrSBAR\n",
    "    \n",
    "\n",
    "def find_boundary_nodes(A, S):\n",
    "    nn = A.shape[0]\n",
    "    magS = len(S)\n",
    "    \n",
    "    nbrS = []\n",
    "    nbrSBAR = []\n",
    "    for ii in range(0, magS):\n",
    "        for jj in range(0, nn):\n",
    "            if A[V_s[ii], jj] != 0:\n",
    "                if not jj in S:\n",
    "                    nbrSBAR.append(jj)\n",
    "                else:\n",
    "                    nbrS.append(jj)\n",
    "                    \n",
    "    return nbrS, nbrSBAR\n",
    "\n",
    "def choose_optimal_node(A, S):\n",
    "    nS, nSBAR = find_boundary_nodes(A, S)\n",
    "    if nSBAR.size == 0:\n",
    "        print \"There are no neighbors to S outside of S\"\n",
    "        return 0\n",
    "    nSBAR_size = nSBAR.size\n",
    "    \n",
    "    XSN_facor = np.zeros((SBAR_size, 1))\n",
    "    # For each node just outside S...\n",
    "    for i in range(0, nSBAR_size):\n",
    "        # Find its neighbors\n",
    "        t_neighb, t_neighbSBAR = find_neighb(A, S, nSBAR[i])\n",
    "        XSN_factor = t_neighbSBAR.size\n",
    "        \n",
    "    ######\n",
    "\n",
    "def graph_sampling_algo_snowball_expansion_sampling(A, f):\n",
    "    n = A.shape[0]\n",
    "    A_s = np.copy(A)\n",
    "    \n",
    "    if f > 1 or f < 0:\n",
    "        print \"Warning: f param not a proper fraction in FS algo\"\n",
    "        return A\n",
    "    \n",
    "    adj_mat = np.where(A != 0, 1, 0)\n",
    "    num_edges_total = compute_graph_volume(adj_mat)\n",
    "    num_edges_to_sample = np.ceil(f * num_edges_total)\n",
    "    \n",
    "    # Select starting node from discrete uniform\n",
    "    current_node = np.random.randint(0, n)\n",
    "    \n",
    "    # Create a list of sampled nodes\n",
    "    V_s = [current_node]\n",
    "    \n",
    "    # Keep track of number of edges sampled\n",
    "    num_edges_sampled = 0\n",
    "    \n",
    "    while num_edges_sampled < num_edges_to_sample:\n",
    "        # Choose the optimal expansion node and add it to the sample\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 3, 4],\n",
       "       [0, 3, 0, 4],\n",
       "       [0, 4, 4, 0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.array([[0, 2, 3, 4],\n",
    "                 [2, 0, 3, 4],\n",
    "                 [3, 3, 0, 4],\n",
    "                 [4, 4, 4, 0]])\n",
    "z[0, :] = 0\n",
    "z[:, 0] = 0\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 4],\n",
       "       [0, 0, 0, 4],\n",
       "       [0, 4, 4, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sampling_algo_metropolis_hastings_random_walk(z, 0.5, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  4.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  4.,  0.,  0.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sampling_algo_uniform_edge_sampling(test, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 7, 3, 4, 8, 9, 0, 2, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "np.random.shuffle(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
